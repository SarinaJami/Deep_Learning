{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbfjPuqaot0X"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mFailed to start the Kernel 'venv'. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Activating /usr/local/bin/python3 to run Jupyter failed with function toString() { [native code] }"
          ]
        }
      ],
      "source": [
        "**Introduction.**\n",
        "\n",
        "work with the MNIST dataset, which consists of images containing one of possibly ten digits, ranging from zero to nine.  Your goal will be to solve the MNIST problem (i.e., assign a digit label to each test image as accurately as possible) using custom-built deep learning models. Below there are a series of \"problems\", and each problem asks you to write some Python code to achieve a goal (e.g., train a neural network, or define a custom neural network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tWmLFsiZo__U",
        "outputId": "f9ab17b4-732f-48a2-901c-64a6f6444e10"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB4_VV0GpKSC"
      },
      "outputs": [],
      "source": [
        "# Fill in the details for the \"transform\" variable\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.05), (0.05))])\n",
        "\n",
        "# We will use a relatively large batch size of 128 here to\n",
        "#  accelerate the training process\n",
        "batch_size = 128\n",
        "\n",
        "# Download the MNIST dataset and data loaders\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Label the classes\n",
        "classes = ('zero', 'one', 'two', 'three',\n",
        "           'four', 'five', 'six', 'seven', 'eight', 'nine')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SIPBiHzpgew",
        "outputId": "e9914659-9d5b-4691-febb-b13a94402eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of train data: 60000\n",
            "Length of test data: 10000\n",
            "Train loader include 469 batches of size 128\n",
            "Train loader include 79 batches of size 128\n",
            "Shape of input image: torch.Size([128, 1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'0 - zero': 0,\n",
              " '1 - one': 1,\n",
              " '2 - two': 2,\n",
              " '3 - three': 3,\n",
              " '4 - four': 4,\n",
              " '5 - five': 5,\n",
              " '6 - six': 6,\n",
              " '7 - seven': 7,\n",
              " '8 - eight': 8,\n",
              " '9 - nine': 9}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get info from dataset\n",
        "print(f\"Length of train data: {len(trainset)}\\nLength of test data: {len(testset)}\")\n",
        "\n",
        "img, label = next(iter(trainloader))\n",
        "print(f\"Train loader include {len(trainloader)} batches of size {img.shape[0]}\")\n",
        "test_img, test_label = next(iter(testloader))\n",
        "print(f\"Train loader include {len(testloader)} batches of size {test_img.shape[0]}\")\n",
        "print(f\"Shape of input image: {img.shape}\")\n",
        "\n",
        "class_names = trainset.classes\n",
        "class_name_idx = trainset.class_to_idx\n",
        "class_name_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "6UIArGTPp10x",
        "outputId": "3e0f4151-216b-4c7a-8929-9fe9cb7abf09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(-0.5, 27.5, 27.5, -0.5)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize input data\n",
        "# Generate a random int in range of trainset size\n",
        "rand_idx = torch.randint(low=0, high=len(trainset), size=(1,))\n",
        "sample = trainset[rand_idx.item()][0] / 20 + 0.05 # Unnormalize\n",
        "plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[trainset[rand_idx.item()][1]])\n",
        "plt.axis(False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LcBE5FappPGD"
      },
      "source": [
        "# Problem 1\n",
        "\n",
        "In this problem we will start by creating the most naive architecture to solve an image recognition problem, in which we use only traditional fully-connected layers.  We will progressively move towards a more modern approach and witness improvements in performance that result.\n",
        "\n",
        "**Part (a)**. A fully-connected neural network with 8 total layers of parameters.  Aside from the output layer, each layer has 50 hidden units.  We use ReLU activations.  We will call this network *NetFC*.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlK0bLpCpZS_"
      },
      "outputs": [],
      "source": [
        "class NetFc(nn.Module):\n",
        "    def __init__(self, input_shape, hidden_units, output_shape):\n",
        "      super().__init__()\n",
        "      self.fully_connected_layers = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "      )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      output = self.fully_connected_layers(x)\n",
        "\n",
        "      # Return the output of the network\n",
        "      return output"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CMitbOup1sxG"
      },
      "source": [
        "**Part (b)**. In this part, we will create a function that trains the model for two epochs (i.e., two complete passes over the training data), and prints the loss of the model on each 100th minibatch. We use the Adam optimizer, and a cross entropy loss for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF9JGF2owirK"
      },
      "outputs": [],
      "source": [
        "# This function takes in a pytorch model as 'net', and then trains it for two\n",
        "#  epochs (i.e., two loops over teh entire dataset).  You may want to adjust\n",
        "# the learning rate sometimes and we will pass that in as 'lr'.  You will also\n",
        "# later need to vary the number of epochs of training, so we will pass that in\n",
        "#  as 'n_epochs.  You will also need to pass in the 'trainloader' object to\n",
        "# handle your data. Your function should return the trained model.\n",
        "def trainMyModel(net: torch.nn.Module,\n",
        "                 lr: float,\n",
        "                 trainloader: torch.utils.data.DataLoader,\n",
        "                 n_epochs: int):\n",
        "  # Set a seed for reproducibility\n",
        "  torch.manual_seed(42)\n",
        "  # Define loss function and optimizer\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(params=net.parameters(),\n",
        "                               lr=lr)\n",
        "  # Training loop\n",
        "  for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
        "    # Calculate training loss for each batch of data and zero its value in each epoch\n",
        "    train_loss = 0\n",
        "    for batch, (X, y) in enumerate(trainloader):\n",
        "      # Put tensors into device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      # Put model into training mode\n",
        "      net.train()\n",
        "\n",
        "      # Feed the model with the training data points in the current batch\n",
        "      y_preds = net(X)\n",
        "\n",
        "      # Compute training loss\n",
        "      loss = loss_fn(y_preds, y)\n",
        "      train_loss += loss\n",
        "\n",
        "      # Zero the previous accumulated gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Calculate gradients in loss function\n",
        "      loss.backward()\n",
        "\n",
        "      # Update weight and bias parameters w.r.t gradients\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print out the process every 100 minibatch\n",
        "      if batch % 100 == 0:\n",
        "        print(f\"Batch {batch}/{len(trainloader)} --- Loss: {train_loss/(batch + 1)}\")\n",
        "\n",
        "  print('Finished Training')\n",
        "  return net\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QkwPMhZ21y94"
      },
      "source": [
        "**Part (c)**. In this part, we will create a function that will take a trained model as input, and a data loader (for our test data), and return the accuracy of the model on the testing data.  The accuracy is reported to at least two decimal places. This function need not be general, but it should work with the 'testloader' that was created above for the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvq_t-Mwyzrv"
      },
      "outputs": [],
      "source": [
        "# This function takes in a pytorch model as 'trainedNet', and then applied it\n",
        "# to testing data that can be loaded using the 'testloader' object.  The\n",
        "# function returns the accuracy of trainedNet on the whole testing dataset\n",
        "# and prints the model's accuracy to the terminal (to at least two decimal\n",
        "#  places of accuracy)\n",
        "\n",
        "# Define accuracy function\n",
        "def accuracy_fn(test_preds, y):\n",
        "  num_correct_preds = torch.eq(test_preds, y).sum().item()\n",
        "  acc = num_correct_preds / len(test_preds) * 100\n",
        "  return acc\n",
        "\n",
        "def testMyModel(trainedNet: torch.nn.Module,\n",
        "                testloader: torch.utils.data.DataLoader):\n",
        "  # Set test accuracy variable to zero in order to add up accuracies of all batches and take average test accuracy\n",
        "  test_acc = 0\n",
        "  # Put the model into testing mode\n",
        "  trainedNet.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in testloader:\n",
        "      # Put tensors into device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      test_logits = trainedNet(X)\n",
        "      # Pass through softmax function and take the max argument\n",
        "      test_preds = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
        "      test_acc += accuracy_fn(test_preds, y)\n",
        "  test_acc /= len(testloader)\n",
        "  print(f'Accuracy of the network on the 10000 test images: {test_acc} %')\n",
        "  return test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWOMYMOa0069",
        "outputId": "46f38130-7345-42ba-bc13-53a88ffc2c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "Batch 0/469 --- Loss: 2.305591106414795\n",
            "Batch 100/469 --- Loss: 0.9684598445892334\n",
            "Batch 200/469 --- Loss: 0.6927343010902405\n",
            "Batch 300/469 --- Loss: 0.5761390924453735\n",
            "Batch 400/469 --- Loss: 0.5087199211120605\n",
            "Epoch 2/2\n",
            "Batch 0/469 --- Loss: 0.16010013222694397\n",
            "Batch 100/469 --- Loss: 0.25883546471595764\n",
            "Batch 200/469 --- Loss: 0.2430177628993988\n",
            "Batch 300/469 --- Loss: 0.24098831415176392\n",
            "Batch 400/469 --- Loss: 0.23913398385047913\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 94.56091772151899 %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "94.56091772151899"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train your model.\n",
        "net = NetFc(input_shape=28*28, hidden_units=50, output_shape=10).to(device);\n",
        "lr = 0.01;\n",
        "n_epochs = 2;\n",
        "trainedNet = trainMyModel(net,lr,trainloader,n_epochs);\n",
        "\n",
        "# Test your model\n",
        "testMyModel(trainedNet,testloader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0GP-2EdZ2mFe"
      },
      "source": [
        "# Problem 2\n",
        "\n",
        "Now we will see the advantages of skip connections in a deep neural network.  We create another fully connected neural network called *NetFcRes* that has two \"skip connections\" in it.  By \"skip connection\", this mean a direct connection from an earlier layer *directly* to a later layer in the network. For example, a skip connection between the first layer and third layer means that the input to the fourth layer is the sum of the output of first layer and the third layers. In this problem, we create a network with two skip connections: one from the output of the first layer to the output of the third layer; and one from the output of the fifth layer to  the output of the 7th layer.  Then, we use our training and testing functions to train and evaluate the performance of the *NetFcRes* model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sgkv7PS5h6u"
      },
      "outputs": [],
      "source": [
        "class NetFcRes(nn.Module):\n",
        "    def __init__(self, input_shape, hidden_units, output_shape):\n",
        "      super().__init__()\n",
        "      self.fully_connected_layers = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "          nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      features = []\n",
        "      # Flatten image inputs\n",
        "      layer = self.fully_connected_layers[0]\n",
        "      x = layer(x)\n",
        "      # Store features before fourth layer which takes in the output of two earlier layers\n",
        "      for layer in self.fully_connected_layers[1:4]:\n",
        "        x = layer(x)\n",
        "        # Append features of each layer\n",
        "        features.append(x)\n",
        "        x = F.relu(x)\n",
        "      # Implement the skip connection for the output of first and third layers\n",
        "      x = F.relu(features[0] + features[2])\n",
        "      x = self.fully_connected_layers[4](x)\n",
        "      # Store features before eights layer which takes in the output of two earlier layers\n",
        "      for layer in self.fully_connected_layers[4:-1]:\n",
        "        x = layer(x)\n",
        "        features.append(x)  # store the features\n",
        "        x = F.relu(x)\n",
        "      # Implement the skip connection for the output of fifth and seventh layers\n",
        "      x = F.relu(features[4] + features[6])\n",
        "      y = self.fully_connected_layers[8](x)\n",
        "      # Return the output of the network\n",
        "      return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb1CZEag9Nfe",
        "outputId": "1c1ea5ca-9bc4-4bd8-9cff-dcab8bdbac8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "Batch 0/469 --- Loss: 2.3455593585968018\n",
            "Batch 100/469 --- Loss: 0.6686679720878601\n",
            "Batch 200/469 --- Loss: 0.49398818612098694\n",
            "Batch 300/469 --- Loss: 0.4310563802719116\n",
            "Batch 400/469 --- Loss: 0.3906792998313904\n",
            "Epoch 2/2\n",
            "Batch 0/469 --- Loss: 0.20001967251300812\n",
            "Batch 100/469 --- Loss: 0.25458434224128723\n",
            "Batch 200/469 --- Loss: 0.2462182641029358\n",
            "Batch 300/469 --- Loss: 0.2447207272052765\n",
            "Batch 400/469 --- Loss: 0.2422735095024109\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 94.4620253164557 %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "94.4620253164557"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train your model.\n",
        "net = NetFcRes(input_shape=28*28, hidden_units=50, output_shape=10).to(device);\n",
        "lr = 0.01;\n",
        "n_epochs = 2;\n",
        "trainedNet = trainMyModel(net,lr,trainloader,n_epochs);\n",
        "\n",
        "# Test your model\n",
        "testMyModel(trainedNet,testloader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "50qyiRyOE326"
      },
      "source": [
        "# Problem 3\n",
        "\n",
        "Now we will see the advantages of convolutional structures in a deep neural network. We create convolutional neural network called 'NetCnn' that has the following structure:\n",
        "\n",
        "layer1: 8 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
        "\n",
        "layer2: 16 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
        "\n",
        "layer3: 2x2 max pooling, with stride of 2. No zero-padding.\n",
        "\n",
        "layer4: 32 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
        "\n",
        "layer5: 64 3x3 convolutional filters, one pixel of zero-padding, and stride of one\n",
        "\n",
        "layer6: 2x2 max pooling, with stride of 2. No zero-padding.\n",
        "\n",
        "layer7: a fully connected layer of 50 neurons.\n",
        "\n",
        "Layer8: a fully connected layer of 10 neurons.\n",
        "\n",
        "We assume ReLU activations and will need to decide precisely where to put these activation functions.  If done correctly, we would have a substantial improvement over *NetFcRes*, the fully-connected network with skip connections.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQX4wtXrBCzj"
      },
      "outputs": [],
      "source": [
        "# Convolutional model - adding in convolutional layers\n",
        "\n",
        "class NetCnn(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv_block_1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=1,\n",
        "                    out_channels=8,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=8,\n",
        "                    out_channels=16,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2,\n",
        "                       stride=2)\n",
        "      )\n",
        "      self.conv_block_2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=16,\n",
        "                    out_channels=32,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=32,\n",
        "                    out_channels=64,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2,\n",
        "                       stride=2)\n",
        "      )\n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=64*7*7, out_features=50),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=50, out_features=10)\n",
        "      )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv_block_1(x)\n",
        "      x = self.conv_block_2(x)\n",
        "      output = self.classifier(x)\n",
        "      #Return output of model\n",
        "      return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LatIEWZnaYfF",
        "outputId": "2869368f-693a-4c90-d39a-ea20a53f69a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "Batch 0/469 --- Loss: 2.3040871620178223\n",
            "Batch 100/469 --- Loss: 0.4352353513240814\n",
            "Batch 200/469 --- Loss: 0.2738005518913269\n",
            "Batch 300/469 --- Loss: 0.21233244240283966\n",
            "Batch 400/469 --- Loss: 0.1760067194700241\n",
            "Epoch 2/2\n",
            "Batch 0/469 --- Loss: 0.05593882128596306\n",
            "Batch 100/469 --- Loss: 0.050864577293395996\n",
            "Batch 200/469 --- Loss: 0.04738549143075943\n",
            "Batch 300/469 --- Loss: 0.04457249492406845\n",
            "Batch 400/469 --- Loss: 0.04518839344382286\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 98.77373417721519 %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "98.77373417721519"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train your model.\n",
        "net = NetCnn().to(device);\n",
        "lr = 0.001;\n",
        "n_epochs = 2;\n",
        "\n",
        "trainedNet = trainMyModel(net,lr,trainloader,n_epochs);\n",
        "\n",
        "# Test your model\n",
        "testMyModel(trainedNet,testloader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FZZSHMHXafrF"
      },
      "source": [
        "# Problem 4\n",
        "\n",
        "In this last problem, we will add batch normalization layers to the network.  Batch normalization, and its variants (e.g., \"layer norm\") are another structure that is now widely-used in modern deep neural networks.  In this problem, we will design a neural network called *NetCnnBn* with the exact same structure as 'NetCnn' except we will add two batch normalization layers in the following locations: (i) after the 2nd convolutional layer, and (ii) after the 1st fully connected layer.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcO6o0XKcbtq"
      },
      "outputs": [],
      "source": [
        "# Convolutional model - adding in convolutional layers\n",
        "\n",
        "class NetCnnBn(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv_block_1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=1,\n",
        "                    out_channels=8,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=8,\n",
        "                    out_channels=16,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "          nn.BatchNorm2d(num_features=16),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2,\n",
        "                       stride=2)\n",
        "      )\n",
        "      self.conv_block_2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=16,\n",
        "                    out_channels=32,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=32,\n",
        "                    out_channels=64,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2,\n",
        "                       stride=2)\n",
        "      )\n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=64*7*7, out_features=50),\n",
        "          nn.BatchNorm1d(num_features=50),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=50, out_features=10)\n",
        "      )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv_block_1(x)\n",
        "      x = self.conv_block_2(x)\n",
        "      output = self.classifier(x)\n",
        "      #Return output of model\n",
        "      return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdo3v8Omd63o",
        "outputId": "e54cab0b-333f-49e2-ba7a-b273327c3abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "Batch 0/469 --- Loss: 2.453518867492676\n",
            "Batch 100/469 --- Loss: 0.5858493447303772\n",
            "Batch 200/469 --- Loss: 0.36083585023880005\n",
            "Batch 300/469 --- Loss: 0.2680508494377136\n",
            "Batch 400/469 --- Loss: 0.21644000709056854\n",
            "Epoch 2/2\n",
            "Batch 0/469 --- Loss: 0.06092465668916702\n",
            "Batch 100/469 --- Loss: 0.038225382566452026\n",
            "Batch 200/469 --- Loss: 0.03433413431048393\n",
            "Batch 300/469 --- Loss: 0.03286709636449814\n",
            "Batch 400/469 --- Loss: 0.03331935405731201\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 98.82318037974683 %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "98.82318037974683"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train your model.\n",
        "net = NetCnnBn().to(device);\n",
        "lr = 0.001;\n",
        "n_epochs = 2;\n",
        "trainedNet = trainMyModel(net,lr,trainloader,n_epochs);\n",
        "\n",
        "# Test your model\n",
        "testMyModel(trainedNet,testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoQkOX4Wd9tD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
